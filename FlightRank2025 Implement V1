{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.18","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ====================== Step 0: Setup ======================\nimport os\nimport numpy as np\nimport pandas as pd\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# Print input files (optional debug)\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# ====================== Step 1: Load and Explore Data ======================\ndata_path = \"/kaggle/input/aeroclub-recsys-2025/train.parquet\"\ndf = pd.read_parquet(data_path)  # ✅ Corrected the variable usage\n\nprint(\"Shape:\", df.shape)\nprint(\"Columns:\", df.columns.tolist())\nprint(df.head())\n\n# ====================== Step 2: Clean and Preprocess ======================\n\n# Fill missing values in selected categorical features\ndf['sex'] = df['sex'].fillna('unknown')\ndf['searchRoute'] = df['searchRoute'].fillna('UNKNOWN')\n\n# Drop rows with missing essential columns (target or key features)\ndf = df.dropna(subset=['selected', 'totalPrice'])  # ✅ Corrected column name\n\n# ====================== Step 3: Split Train/Test ======================\n\n# Use 'dataset' column if it exists to split\nif 'dataset' in df.columns:\n    train = df[df['dataset'] == 'train'].copy()\n    test = df[df['dataset'] == 'test'].copy()\nelse:\n    # Otherwise, do an 80/20 random split\n    from sklearn.model_selection import train_test_split\n    train, test = train_test_split(df, test_size=0.2, random_state=42)\n\nprint(\"Train size:\", train.shape)\nprint(\"Test size:\", test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T17:50:41.015794Z","iopub.execute_input":"2025-08-06T17:50:41.016077Z","iopub.status.idle":"2025-08-06T17:54:59.235649Z","shell.execute_reply.started":"2025-08-06T17:50:41.016051Z","shell.execute_reply":"2025-08-06T17:54:59.229970Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/aeroclub-recsys-2025/jsons_raw.tar.kaggle\n/kaggle/input/aeroclub-recsys-2025/train.parquet\n/kaggle/input/aeroclub-recsys-2025/sample_submission.parquet\n/kaggle/input/aeroclub-recsys-2025/jsons_structure.md\n/kaggle/input/aeroclub-recsys-2025/test.parquet\nShape: (18145372, 126)\nColumns: ['Id', 'bySelf', 'companyID', 'corporateTariffCode', 'frequentFlyer', 'nationality', 'isAccess3D', 'isVip', 'legs0_arrivalAt', 'legs0_departureAt', 'legs0_duration', 'legs0_segments0_aircraft_code', 'legs0_segments0_arrivalTo_airport_city_iata', 'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_baggageAllowance_quantity', 'legs0_segments0_baggageAllowance_weightMeasurementType', 'legs0_segments0_cabinClass', 'legs0_segments0_departureFrom_airport_iata', 'legs0_segments0_duration', 'legs0_segments0_flightNumber', 'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code', 'legs0_segments0_seatsAvailable', 'legs0_segments1_aircraft_code', 'legs0_segments1_arrivalTo_airport_city_iata', 'legs0_segments1_arrivalTo_airport_iata', 'legs0_segments1_baggageAllowance_quantity', 'legs0_segments1_baggageAllowance_weightMeasurementType', 'legs0_segments1_cabinClass', 'legs0_segments1_departureFrom_airport_iata', 'legs0_segments1_duration', 'legs0_segments1_flightNumber', 'legs0_segments1_marketingCarrier_code', 'legs0_segments1_operatingCarrier_code', 'legs0_segments1_seatsAvailable', 'legs0_segments2_aircraft_code', 'legs0_segments2_arrivalTo_airport_city_iata', 'legs0_segments2_arrivalTo_airport_iata', 'legs0_segments2_baggageAllowance_quantity', 'legs0_segments2_baggageAllowance_weightMeasurementType', 'legs0_segments2_cabinClass', 'legs0_segments2_departureFrom_airport_iata', 'legs0_segments2_duration', 'legs0_segments2_flightNumber', 'legs0_segments2_marketingCarrier_code', 'legs0_segments2_operatingCarrier_code', 'legs0_segments2_seatsAvailable', 'legs0_segments3_aircraft_code', 'legs0_segments3_arrivalTo_airport_city_iata', 'legs0_segments3_arrivalTo_airport_iata', 'legs0_segments3_baggageAllowance_quantity', 'legs0_segments3_baggageAllowance_weightMeasurementType', 'legs0_segments3_cabinClass', 'legs0_segments3_departureFrom_airport_iata', 'legs0_segments3_duration', 'legs0_segments3_flightNumber', 'legs0_segments3_marketingCarrier_code', 'legs0_segments3_operatingCarrier_code', 'legs0_segments3_seatsAvailable', 'legs1_arrivalAt', 'legs1_departureAt', 'legs1_duration', 'legs1_segments0_aircraft_code', 'legs1_segments0_arrivalTo_airport_city_iata', 'legs1_segments0_arrivalTo_airport_iata', 'legs1_segments0_baggageAllowance_quantity', 'legs1_segments0_baggageAllowance_weightMeasurementType', 'legs1_segments0_cabinClass', 'legs1_segments0_departureFrom_airport_iata', 'legs1_segments0_duration', 'legs1_segments0_flightNumber', 'legs1_segments0_marketingCarrier_code', 'legs1_segments0_operatingCarrier_code', 'legs1_segments0_seatsAvailable', 'legs1_segments1_aircraft_code', 'legs1_segments1_arrivalTo_airport_city_iata', 'legs1_segments1_arrivalTo_airport_iata', 'legs1_segments1_baggageAllowance_quantity', 'legs1_segments1_baggageAllowance_weightMeasurementType', 'legs1_segments1_cabinClass', 'legs1_segments1_departureFrom_airport_iata', 'legs1_segments1_duration', 'legs1_segments1_flightNumber', 'legs1_segments1_marketingCarrier_code', 'legs1_segments1_operatingCarrier_code', 'legs1_segments1_seatsAvailable', 'legs1_segments2_aircraft_code', 'legs1_segments2_arrivalTo_airport_city_iata', 'legs1_segments2_arrivalTo_airport_iata', 'legs1_segments2_baggageAllowance_quantity', 'legs1_segments2_baggageAllowance_weightMeasurementType', 'legs1_segments2_cabinClass', 'legs1_segments2_departureFrom_airport_iata', 'legs1_segments2_duration', 'legs1_segments2_flightNumber', 'legs1_segments2_marketingCarrier_code', 'legs1_segments2_operatingCarrier_code', 'legs1_segments2_seatsAvailable', 'legs1_segments3_aircraft_code', 'legs1_segments3_arrivalTo_airport_city_iata', 'legs1_segments3_arrivalTo_airport_iata', 'legs1_segments3_baggageAllowance_quantity', 'legs1_segments3_baggageAllowance_weightMeasurementType', 'legs1_segments3_cabinClass', 'legs1_segments3_departureFrom_airport_iata', 'legs1_segments3_duration', 'legs1_segments3_flightNumber', 'legs1_segments3_marketingCarrier_code', 'legs1_segments3_operatingCarrier_code', 'legs1_segments3_seatsAvailable', 'miniRules0_monetaryAmount', 'miniRules0_percentage', 'miniRules0_statusInfos', 'miniRules1_monetaryAmount', 'miniRules1_percentage', 'miniRules1_statusInfos', 'pricingInfo_isAccessTP', 'pricingInfo_passengerCount', 'profileId', 'ranker_id', 'requestDate', 'searchRoute', 'sex', 'taxes', 'totalPrice', 'selected']\n   Id  bySelf  companyID  corporateTariffCode frequentFlyer  nationality  \\\n0   0    True      57323                 <NA>      S7/SU/UT           36   \n1   1    True      57323                  123      S7/SU/UT           36   \n2   2    True      57323                 <NA>      S7/SU/UT           36   \n3   3    True      57323                  123      S7/SU/UT           36   \n4   4    True      57323                 <NA>      S7/SU/UT           36   \n\n   isAccess3D  isVip      legs0_arrivalAt    legs0_departureAt  ...  \\\n0       False  False  2024-06-15T16:20:00  2024-06-15T15:40:00  ...   \n1        True  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n2       False  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n3        True  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n4       False  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n\n  pricingInfo_isAccessTP pricingInfo_passengerCount profileId  \\\n0                    1.0                          1   2087645   \n1                    1.0                          1   2087645   \n2                    1.0                          1   2087645   \n3                    1.0                          1   2087645   \n4                    1.0                          1   2087645   \n\n                          ranker_id         requestDate    searchRoute   sex  \\\n0  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n1  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n2  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n3  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n4  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n\n    taxes totalPrice selected  \n0   370.0    16884.0        1  \n1  2240.0    51125.0        0  \n2  2240.0    53695.0        0  \n3  2240.0    81880.0        0  \n4  2240.0    86070.0        0  \n\n[5 rows x 126 columns]\nTrain size: (14516297, 126)\nTest size: (3629075, 126)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ==================== IMPORTS ====================\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.model_selection import GroupShuffleSplit\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nimport joblib\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# ==================== CONSTANTS ====================\nCATEGORICAL_FEATURES = ['frequentFlyer', 'sex', 'searchRoute']\nNUMERICAL_FEATURES = [\n    'totalPrice', 'taxes', 'legs0_duration', 'legs1_duration',\n    'price_per_hour', 'price_rank', 'hour_of_day', 'days_until_flight'\n]\nMIN_GROUP_SIZE = 10\nMAX_CARDINALITY = 250\n\n# ==================== DATA LOADING ====================\ndef load_data(train_path, test_path):\n    \"\"\"Load and validate competition data with type conversion\"\"\"\n    train = pd.read_parquet(train_path)\n    test = pd.read_parquet(test_path)\n    \n    # Convert numeric columns\n    numeric_cols = ['totalPrice', 'taxes', 'legs0_duration', 'legs1_duration']\n    for df in [train, test]:\n        for col in numeric_cols:\n            if col in df.columns:\n                df[col] = pd.to_numeric(df[col], errors='coerce')\n    \n    # Verify columns\n    train_required = {'ranker_id', 'selected', 'totalPrice'}\n    test_required = {'ranker_id', 'totalPrice', 'Id'}\n    \n    train_missing = train_required - set(train.columns)\n    test_missing = test_required - set(test.columns)\n    \n    if train_missing:\n        raise ValueError(f\"Train data missing columns: {train_missing}\")\n    if test_missing:\n        raise ValueError(f\"Test data missing columns: {test_missing}\")\n    \n    return train, test\n\n# ==================== FEATURE ENGINEERING ====================\ndef reduce_cardinality(df, col, max_categories=MAX_CARDINALITY):\n    \"\"\"Reduce high-cardinality categorical features\"\"\"\n    if col in df.columns and df[col].nunique() > max_categories:\n        counts = df[col].value_counts()\n        keep = counts.nlargest(max_categories - 1).index\n        df[col] = np.where(df[col].isin(keep), df[col], 'OTHER')\n    return df\n\ndef create_features(df):\n    \"\"\"Create features with robust type handling\"\"\"\n    # 1. Reduce high-cardinality features\n    for col in CATEGORICAL_FEATURES:\n        df = reduce_cardinality(df, col)\n    \n    # 2. Ensure numeric types\n    for col in ['legs0_duration', 'legs1_duration', 'totalPrice', 'taxes']:\n        if col in df.columns:\n            df[col] = pd.to_numeric(df[col], errors='coerce')\n    \n    # Set defaults for missing durations\n    df['legs0_duration'] = df.get('legs0_duration', 120).fillna(120)\n    df['legs1_duration'] = df.get('legs1_duration', 60).fillna(60)\n    \n    # 3. Create derived features\n    df['total_duration'] = df['legs0_duration'] + df['legs1_duration']\n    df['price_per_hour'] = df['totalPrice'] / (df['total_duration']/60 + 1e-6)\n    df['price_rank'] = df.groupby('ranker_id')['totalPrice'].rank()\n    \n    # 4. Handle dates\n    time_col = 'searchTime' if 'searchTime' in df.columns else 'requestDate'\n    if time_col in df.columns:\n        dt = pd.to_datetime(df[time_col])\n        df['hour_of_day'] = dt.dt.hour\n        if 'departureDate' in df.columns:\n            df['days_until_flight'] = (pd.to_datetime(df['departureDate']) - dt).dt.days\n    df['hour_of_day'] = df.get('hour_of_day', 12)\n    df['days_until_flight'] = df.get('days_until_flight', 7)\n    \n    return df\n\n# ==================== PREPROCESSING ====================\ndef build_preprocessor():\n    \"\"\"Create sklearn pipeline with proper type handling\"\"\"\n    numeric_transformer = Pipeline([\n        ('imputer', SimpleImputer(strategy='median')),\n    ])\n    \n    categorical_transformer = Pipeline([\n        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n    ])\n    \n    return ColumnTransformer([\n        ('num', numeric_transformer, NUMERICAL_FEATURES),\n        ('cat', categorical_transformer, CATEGORICAL_FEATURES)\n    ])\n\n# ==================== MODEL TRAINING ====================\ndef train_model(X, y, groups, preprocessor):\n    \"\"\"Train with group-aware cross validation\"\"\"\n    model = HistGradientBoostingClassifier(\n        max_iter=500,\n        early_stopping=True,\n        random_state=42,\n        categorical_features=[X.columns.get_loc(c) for c in CATEGORICAL_FEATURES if c in X.columns],\n        max_bins=255,\n        class_weight='balanced',\n        verbose=1\n    )\n    \n    # Group-aware split\n    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n    train_idx, val_idx = next(gss.split(X, y, groups=groups))\n    \n    # Fit preprocessing\n    X_train = preprocessor.fit_transform(X.iloc[train_idx])\n    X_val = preprocessor.transform(X.iloc[val_idx])\n    \n    # Train\n    model.fit(X_train, y.iloc[train_idx])\n    \n    # Prepare validation data with group info\n    val_df = X.iloc[val_idx].copy()\n    val_df['ranker_id'] = groups.iloc[val_idx].values\n    val_df.reset_index(drop=True, inplace=True)\n    \n    return model, X_val, y.iloc[val_idx], val_df\n\n# ==================== EVALUATION ====================\ndef calculate_hitrate(val_df, pred_scores, true_values):\n    \"\"\"Calculate exact competition HitRate@3\"\"\"\n    val_df = val_df.copy()\n    val_df['pred_score'] = pred_scores\n    val_df['selected'] = true_values\n    \n    # Filter groups > MIN_GROUP_SIZE\n    group_sizes = val_df.groupby('ranker_id').size()\n    valid_groups = group_sizes[group_sizes > MIN_GROUP_SIZE].index\n    val_df = val_df[val_df['ranker_id'].isin(valid_groups)]\n    \n    # Calculate ranks within each session\n    val_df['rank'] = val_df.groupby('ranker_id')['pred_score'].rank(ascending=False, method='first')\n    \n    # Check if selected item is in top 3\n    hits = val_df[val_df['selected'] == 1]['rank'] <= 3\n    return hits.mean()\n\n# ==================== MAIN PIPELINE ====================\ndef main():\n    # 1. Load and convert data\n    train, test = load_data(\n        \"/kaggle/input/aeroclub-recsys-2025/train.parquet\",\n        \"/kaggle/input/aeroclub-recsys-2025/test.parquet\"\n    )\n    \n    # 2. Feature engineering\n    train = create_features(train)\n    test = create_features(test)\n    \n    # 3. Filter small groups (training only)\n    if 'selected' in train.columns:\n        group_sizes = train['ranker_id'].value_counts()\n        valid_groups = group_sizes[group_sizes > MIN_GROUP_SIZE].index\n        train = train[train['ranker_id'].isin(valid_groups)]\n    \n    # 4. Prepare modeling data\n    X = train[NUMERICAL_FEATURES + CATEGORICAL_FEATURES]\n    y = train['selected']\n    groups = train['ranker_id']\n    \n    # 5. Train model\n    preprocessor = build_preprocessor()\n    model, X_val, y_val, val_df = train_model(X, y, groups, preprocessor)\n    \n    # 6. Validate\n    val_pred = model.predict_proba(X_val)[:, 1]\n    hr3 = calculate_hitrate(val_df, val_pred, y_val)\n    print(f\"Validation HitRate@3: {hr3:.4f}\")\n    \n    # 7. Generate submission\n    X_test = test[NUMERICAL_FEATURES + CATEGORICAL_FEATURES]\n    test_processed = preprocessor.transform(X_test)\n    test['pred_score'] = model.predict_proba(test_processed)[:, 1]\n    \n    # Create ranks within each group\n    test['rank'] = test.groupby('ranker_id')['pred_score'].rank(ascending=False, method='dense').astype(int)\n    \n    # Prepare final submission (ensure we keep original test order)\n    submission = test[['Id', 'rank']].copy()\n    submission = submission.rename(columns={'rank': 'selected'})\n    \n    # 8. Save submission\n    submission.to_parquet(\"submission.parquet\", index=False)\n    \n    # 9. Save pipeline\n    joblib.dump({\n        'model': model,\n        'preprocessor': preprocessor,\n        'features': NUMERICAL_FEATURES + CATEGORICAL_FEATURES\n    }, 'pipeline.pkl')\n    \n    print(\"\\n✅ Submission saved to submission.parquet\")\n    print(\"Sample predictions:\")\n    print(submission.head())\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T19:12:33.498261Z","iopub.execute_input":"2025-08-06T19:12:33.498730Z","iopub.status.idle":"2025-08-06T19:17:10.620956Z","shell.execute_reply.started":"2025-08-06T19:12:33.498701Z","shell.execute_reply":"2025-08-06T19:17:10.616015Z"}},"outputs":[{"name":"stdout","text":"Binning 1.150 GB of training data: 0.801 s\nBinning 0.128 GB of validation data: 0.048 s\nFitting gradient boosted rounds:\nFit 141 trees in 77.568 s, (4371 total leaves)\nTime spent computing histograms: 18.997s\nTime spent finding best splits:  0.462s\nTime spent applying splits:      2.829s\nTime spent predicting:           3.163s\nValidation HitRate@3: 0.0190\n\n✅ Submission saved to submission.parquet\nSample predictions:\n                Id  selected\n18144679  18144679         1\n18144680  18144680         9\n18144681  18144681        12\n18144682  18144682        24\n18144683  18144683        26\n","output_type":"stream"}],"execution_count":1}]}