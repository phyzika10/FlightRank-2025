{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":105399,"databundleVersionId":12733338,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-06T11:04:26.807167Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# 📌 Load only required columns to save memory\ncolumns_needed = [\n    'Id', 'totalPrice', 'taxes', 'frequentFlyer',\n    'legs0_duration', 'legs1_duration', 'pricingInfo_passengerCount',\n    'selected', 'requestDate', 'searchRoute', 'sex'\n]\n\ndf = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/train.parquet', columns=columns_needed)\n\n# ✅ Convert 'requestDate' to datetime\ndf['requestDate'] = pd.to_datetime(df['requestDate'], errors='coerce')\n\n# ✅ Convert duration strings (e.g., \"02:40:00\") to minutes\ndef time_str_to_minutes(x):\n    try:\n        t = pd.to_timedelta(x)\n        return t.total_seconds() / 60\n    except:\n        return None\n\nfor col in ['legs0_duration', 'legs1_duration']:\n    df[col] = df[col].apply(time_str_to_minutes).astype('float32')\n\n# ✅ Downcast numeric columns\nfor col in ['totalPrice', 'taxes', 'pricingInfo_passengerCount']:\n    df[col] = pd.to_numeric(df[col], downcast='float')\n\n# ✅ Convert 'selected' to int8\ndf['selected'] = df['selected'].astype('int8')\n\n# ✅ Encode categorical columns\nfor col in ['searchRoute', 'sex', 'frequentFlyer']:\n    df[col] = df[col].astype('category')\n    df[col] = LabelEncoder().fit_transform(df[col])\n\n# ✅ Create query_group\ndf['query_group'] = df['Id']\n\n# ✅ Print results\nprint(\"\\n✅ Data types after optimization:\\n\", df.dtypes)\nprint(\"\\n✅ Memory usage (MB):\", df.memory_usage(deep=True).sum() / 1024**2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Make a copy to avoid overwriting original\ndf_fe = df.copy()\n\n# 🕒 Total duration\ndf_fe['total_duration'] = df_fe['legs0_duration'] + df_fe['legs1_duration']\n\n# 🔁 Has connection (1 if second leg exists, else 0)\ndf_fe['has_connection'] = (df_fe['legs1_duration'] > 0).astype('int8')\n\n# 💸 Price per passenger\ndf_fe['price_per_passenger'] = df_fe['totalPrice'] / (df_fe['pricingInfo_passengerCount'] + 1e-5)  # avoid div/0\n\n# 📅 Time features from requestDate\ndf_fe['request_dayofweek'] = df_fe['requestDate'].dt.dayofweek.astype('int8')  # 0=Monday\ndf_fe['request_hour'] = df_fe['requestDate'].dt.hour.astype('int8')\ndf_fe['request_month'] = df_fe['requestDate'].dt.month.astype('int8')\n\n# 🧼 Drop original datetime if no longer needed\n# df_fe.drop(columns=['requestDate'], inplace=True)\n\n# 🧠 Preview result\nprint(df_fe[['total_duration', 'has_connection', 'price_per_passenger', 'request_dayofweek', 'request_hour', 'request_month']].head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_fe.to_csv(\"/kaggle/working//train_fe.csv\", index=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install pyarrow\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_fe.to_parquet(\"/kaggle/working/train_fe.parquet\", index=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import lightgbm as lgb\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# ✅ Define features to use\nfeatures = [\n    'totalPrice', 'taxes', 'frequentFlyer',\n    'legs0_duration', 'legs1_duration',\n    'pricingInfo_passengerCount',\n    'searchRoute', 'sex'\n]\n\ntarget = 'selected'\n\n# ✅ Group by query (example: each 'Id' is a separate query)\ndf_fe['query_group'] = df_fe['Id']  # or use 'requestDate' + 'searchRoute'\n\n# ✅ Sort to keep group structure\ndf_fe = df_fe.sort_values(by='query_group')\n\n# ✅ Split into train/val\ntrain_df, val_df = train_test_split(df_fe, test_size=0.2, random_state=42, stratify=df_fe['selected'])\n\n# ✅ Create LightGBM datasets\nimport lightgbm as lgb\n\nX_train = train_df[features]\ny_train = train_df['selected']\ngroup_train = train_df.groupby('query_group').size().values\n\nX_val = val_df[features]\ny_val = val_df['selected']\ngroup_val = val_df.groupby('query_group').size().values\n\n\ndtrain = lgb.Dataset(X_train, label=y_train, group=group_train)\ndval = lgb.Dataset(X_val, label=y_val, group=group_val)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lightgbm import early_stopping, log_evaluation\nparams = {\n    'objective': 'lambdarank',\n    'metric': 'ndcg',\n    'ndcg_eval_at': [3],\n    'boosting_type': 'gbdt',\n    'learning_rate': 0.05,\n    'num_leaves': 31,\n    'min_data_in_leaf': 20,\n    'verbose': -1\n}\n\nfrom sklearn.model_selection import GroupShuffleSplit\n\ngss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\ntrain_idx, val_idx = next(gss.split(df, groups=df['query_group']))\n\ndf_train = df.iloc[train_idx]\ndf_val = df.iloc[val_idx]\n\nmodel = lgb.train(\n    params,\n    dtrain,\n    valid_sets=[dtrain, dval],\n    valid_names=['train', 'valid'],\n    num_boost_round=1000,\n    callbacks=[\n        early_stopping(stopping_rounds=100),\n        log_evaluation(period=100)\n    ]\n)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\ntrain_groups = set(df_train['query_group'])\nval_groups = set(df_val['query_group'])\nprint(\"Overlap:\", len(train_groups & val_groups))  # should be 0\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.feature_importance()\nmodel.feature_name()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features = ['totalPrice', 'taxes', 'frequentFlyer', 'legs0_duration',\n            'legs1_duration', 'pricingInfo_passengerCount', 'searchRoute', 'sex']\n\ndtrain = lgb.Dataset(df_train[features], label=df_train['selected'], group=df_train.groupby('query_group').size().values)\ndval = lgb.Dataset(df_val[features], label=df_val['selected'], group=df_val.groupby('query_group').size().values)\n\nprint(len(set(df_train['query_group']) & set(df_val['query_group'])))  # should be 0\nprint(df_train.columns)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def hit_rate_at_k(df_pred, k=3):\n    hits = 0\n    total = 0\n    for _, group in df_pred.groupby(\"query_group\"):\n        top_k = group.sort_values(\"pred\", ascending=False).head(k)\n        if top_k[\"selected\"].sum() > 0:\n            hits += 1\n        total += 1\n    return hits / total\n\ndf_val_pred = df_val.copy()\ndf_val_pred['pred'] = model.predict(df_val[features])\nhr3 = hit_rate_at_k(df_val_pred, k=3)\nprint(f\"\\n🎯 HitRate@3: {hr3:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}