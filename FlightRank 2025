{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":105399,"databundleVersionId":12733338,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-04T03:25:02.703377Z","iopub.execute_input":"2025-08-04T03:25:02.703774Z","iopub.status.idle":"2025-08-04T03:25:03.149819Z","shell.execute_reply.started":"2025-08-04T03:25:02.703742Z","shell.execute_reply":"2025-08-04T03:25:03.148540Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/aeroclub-recsys-2025/jsons_raw.tar.kaggle\n/kaggle/input/aeroclub-recsys-2025/train.parquet\n/kaggle/input/aeroclub-recsys-2025/sample_submission.parquet\n/kaggle/input/aeroclub-recsys-2025/jsons_structure.md\n/kaggle/input/aeroclub-recsys-2025/test.parquet\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# ðŸ“Œ Load only required columns to save memory\ncolumns_needed = [\n    'Id', 'totalPrice', 'taxes', 'frequentFlyer',\n    'legs0_duration', 'legs1_duration', 'pricingInfo_passengerCount',\n    'selected', 'requestDate', 'searchRoute', 'sex'\n]\n\ndf = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/train.parquet', columns=columns_needed)\n\n# âœ… Convert 'requestDate' to datetime\ndf['requestDate'] = pd.to_datetime(df['requestDate'], errors='coerce')\n\n# âœ… Convert duration strings (e.g., \"02:40:00\") to minutes\ndef time_str_to_minutes(x):\n    try:\n        t = pd.to_timedelta(x)\n        return t.total_seconds() / 60\n    except:\n        return None\n\nfor col in ['legs0_duration', 'legs1_duration']:\n    df[col] = df[col].apply(time_str_to_minutes).astype('float32')\n\n# âœ… Downcast numeric columns\nfor col in ['totalPrice', 'taxes', 'pricingInfo_passengerCount']:\n    df[col] = pd.to_numeric(df[col], downcast='float')\n\n# âœ… Convert 'selected' to int8\ndf['selected'] = df['selected'].astype('int8')\n\n# âœ… Encode categorical columns\nfor col in ['searchRoute', 'sex', 'frequentFlyer']:\n    df[col] = df[col].astype('category')\n    df[col] = LabelEncoder().fit_transform(df[col])\n\n# âœ… Create query_group\ndf['query_group'] = df['Id']\n\n# âœ… Print results\nprint(\"\\nâœ… Data types after optimization:\\n\", df.dtypes)\nprint(\"\\nâœ… Memory usage (MB):\", df.memory_usage(deep=True).sum() / 1024**2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T03:25:03.151583Z","iopub.execute_input":"2025-08-04T03:25:03.152120Z","iopub.status.idle":"2025-08-04T03:28:46.675808Z","shell.execute_reply.started":"2025-08-04T03:25:03.152050Z","shell.execute_reply":"2025-08-04T03:28:46.674741Z"}},"outputs":[{"name":"stdout","text":"\nâœ… Data types after optimization:\n Id                                     int64\ntotalPrice                           float32\ntaxes                                float32\nfrequentFlyer                          int64\nlegs0_duration                       float32\nlegs1_duration                       float32\npricingInfo_passengerCount           float32\nselected                                int8\nrequestDate                   datetime64[ns]\nsearchRoute                            int64\nsex                                    int64\nquery_group                            int64\ndtype: object\n\nâœ… Memory usage (MB): 1332.4676933288574\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\n\n# Make a copy to avoid overwriting original\ndf_fe = df.copy()\n\n# ðŸ•’ Total duration\ndf_fe['total_duration'] = df_fe['legs0_duration'] + df_fe['legs1_duration']\n\n# ðŸ” Has connection (1 if second leg exists, else 0)\ndf_fe['has_connection'] = (df_fe['legs1_duration'] > 0).astype('int8')\n\n# ðŸ’¸ Price per passenger\ndf_fe['price_per_passenger'] = df_fe['totalPrice'] / (df_fe['pricingInfo_passengerCount'] + 1e-5)  # avoid div/0\n\n# ðŸ“… Time features from requestDate\ndf_fe['request_dayofweek'] = df_fe['requestDate'].dt.dayofweek.astype('int8')  # 0=Monday\ndf_fe['request_hour'] = df_fe['requestDate'].dt.hour.astype('int8')\ndf_fe['request_month'] = df_fe['requestDate'].dt.month.astype('int8')\n\n# ðŸ§¼ Drop original datetime if no longer needed\n# df_fe.drop(columns=['requestDate'], inplace=True)\n\n# ðŸ§  Preview result\nprint(df_fe[['total_duration', 'has_connection', 'price_per_passenger', 'request_dayofweek', 'request_hour', 'request_month']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T03:28:46.676617Z","iopub.execute_input":"2025-08-04T03:28:46.677019Z","iopub.status.idle":"2025-08-04T03:28:50.377409Z","shell.execute_reply.started":"2025-08-04T03:28:46.676995Z","shell.execute_reply":"2025-08-04T03:28:50.376357Z"}},"outputs":[{"name":"stdout","text":"   total_duration  has_connection  price_per_passenger  request_dayofweek  \\\n0           315.0               1         16883.831162                  4   \n1           950.0               1         51124.488755                  4   \n2           950.0               1         53694.463055                  4   \n3           950.0               1         81879.181208                  4   \n4           950.0               1         86069.139309                  4   \n\n   request_hour  request_month  \n0             3              5  \n1             3              5  \n2             3              5  \n3             3              5  \n4             3              5  \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"df_fe.to_csv(\"/kaggle/working//train_fe.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T03:28:50.379776Z","iopub.execute_input":"2025-08-04T03:28:50.380074Z","iopub.status.idle":"2025-08-04T03:32:34.401631Z","shell.execute_reply.started":"2025-08-04T03:28:50.380028Z","shell.execute_reply":"2025-08-04T03:32:34.400332Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"pip install pyarrow\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T03:32:34.403175Z","iopub.execute_input":"2025-08-04T03:32:34.403507Z","iopub.status.idle":"2025-08-04T03:32:39.769565Z","shell.execute_reply.started":"2025-08-04T03:32:34.403475Z","shell.execute_reply":"2025-08-04T03:32:39.768111Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (19.0.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df_fe.to_parquet(\"/kaggle/working/train_fe.parquet\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T03:32:39.771216Z","iopub.execute_input":"2025-08-04T03:32:39.771596Z","iopub.status.idle":"2025-08-04T03:32:48.745286Z","shell.execute_reply.started":"2025-08-04T03:32:39.771550Z","shell.execute_reply":"2025-08-04T03:32:48.744171Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import lightgbm as lgb\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# âœ… Define features to use\nfeatures = [\n    'totalPrice', 'taxes', 'frequentFlyer',\n    'legs0_duration', 'legs1_duration',\n    'pricingInfo_passengerCount',\n    'searchRoute', 'sex'\n]\n\ntarget = 'selected'\n\n# âœ… Group by query (example: each 'Id' is a separate query)\ndf_fe['query_group'] = df_fe['Id']  # or use 'requestDate' + 'searchRoute'\n\n# âœ… Sort to keep group structure\ndf_fe = df_fe.sort_values(by='query_group')\n\n# âœ… Split into train/val\ntrain_df, val_df = train_test_split(df_fe, test_size=0.2, random_state=42, stratify=df_fe['selected'])\n\n# âœ… Create LightGBM datasets\nimport lightgbm as lgb\n\nX_train = train_df[features]\ny_train = train_df['selected']\ngroup_train = train_df.groupby('query_group').size().values\n\nX_val = val_df[features]\ny_val = val_df['selected']\ngroup_val = val_df.groupby('query_group').size().values\n\n\ndtrain = lgb.Dataset(X_train, label=y_train, group=group_train)\ndval = lgb.Dataset(X_val, label=y_val, group=group_val)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T03:35:37.844328Z","iopub.execute_input":"2025-08-04T03:35:37.845614Z","iopub.status.idle":"2025-08-04T03:36:06.810918Z","shell.execute_reply.started":"2025-08-04T03:35:37.845556Z","shell.execute_reply":"2025-08-04T03:36:06.809796Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from lightgbm import early_stopping, log_evaluation\nparams = {\n    'objective': 'lambdarank',\n    'metric': 'ndcg',\n    'ndcg_eval_at': [3],\n    'boosting_type': 'gbdt',\n    'learning_rate': 0.05,\n    'num_leaves': 31,\n    'min_data_in_leaf': 20,\n    'verbose': -1\n}\n\nfrom sklearn.model_selection import GroupShuffleSplit\n\ngss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\ntrain_idx, val_idx = next(gss.split(df, groups=df['query_group']))\n\ndf_train = df.iloc[train_idx]\ndf_val = df.iloc[val_idx]\n\nmodel = lgb.train(\n    params,\n    dtrain,\n    valid_sets=[dtrain, dval],\n    valid_names=['train', 'valid'],\n    num_boost_round=1000,\n    callbacks=[\n        early_stopping(stopping_rounds=100),\n        log_evaluation(period=100)\n    ]\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T03:36:14.375570Z","iopub.execute_input":"2025-08-04T03:36:14.376027Z","iopub.status.idle":"2025-08-04T03:37:52.486472Z","shell.execute_reply.started":"2025-08-04T03:36:14.375992Z","shell.execute_reply":"2025-08-04T03:37:52.485751Z"}},"outputs":[{"name":"stdout","text":"Training until validation scores don't improve for 100 rounds\n[100]\ttrain's ndcg@3: 1\tvalid's ndcg@3: 1\nEarly stopping, best iteration is:\n[1]\ttrain's ndcg@3: 1\tvalid's ndcg@3: 1\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\ntrain_groups = set(df_train['query_group'])\nval_groups = set(df_val['query_group'])\nprint(\"Overlap:\", len(train_groups & val_groups))  # should be 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T03:38:02.729407Z","iopub.execute_input":"2025-08-04T03:38:02.729773Z","iopub.status.idle":"2025-08-04T03:38:06.376176Z","shell.execute_reply.started":"2025-08-04T03:38:02.729746Z","shell.execute_reply":"2025-08-04T03:38:06.375106Z"}},"outputs":[{"name":"stdout","text":"Overlap: 0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"model.feature_importance()\nmodel.feature_name()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T03:38:11.116452Z","iopub.execute_input":"2025-08-04T03:38:11.117892Z","iopub.status.idle":"2025-08-04T03:38:11.126691Z","shell.execute_reply.started":"2025-08-04T03:38:11.117842Z","shell.execute_reply":"2025-08-04T03:38:11.125282Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['totalPrice',\n 'taxes',\n 'frequentFlyer',\n 'legs0_duration',\n 'legs1_duration',\n 'pricingInfo_passengerCount',\n 'searchRoute',\n 'sex']"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"features = ['totalPrice', 'taxes', 'frequentFlyer', 'legs0_duration',\n            'legs1_duration', 'pricingInfo_passengerCount', 'searchRoute', 'sex']\n\ndtrain = lgb.Dataset(df_train[features], label=df_train['selected'], group=df_train.groupby('query_group').size().values)\ndval = lgb.Dataset(df_val[features], label=df_val['selected'], group=df_val.groupby('query_group').size().values)\n\nprint(len(set(df_train['query_group']) & set(df_val['query_group'])))  # should be 0\nprint(df_train.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T03:38:16.182358Z","iopub.execute_input":"2025-08-04T03:38:16.182785Z","iopub.status.idle":"2025-08-04T03:38:25.526918Z","shell.execute_reply.started":"2025-08-04T03:38:16.182754Z","shell.execute_reply":"2025-08-04T03:38:25.525807Z"}},"outputs":[{"name":"stdout","text":"0\nIndex(['Id', 'totalPrice', 'taxes', 'frequentFlyer', 'legs0_duration',\n       'legs1_duration', 'pricingInfo_passengerCount', 'selected',\n       'requestDate', 'searchRoute', 'sex', 'query_group'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def hit_rate_at_k(df_pred, k=3):\n    hits = 0\n    total = 0\n    for _, group in df_pred.groupby(\"query_group\"):\n        top_k = group.sort_values(\"pred\", ascending=False).head(k)\n        if top_k[\"selected\"].sum() > 0:\n            hits += 1\n        total += 1\n    return hits / total\n\ndf_val_pred = df_val.copy()\ndf_val_pred['pred'] = model.predict(df_val[features])\nhr3 = hit_rate_at_k(df_val_pred, k=3)\nprint(f\"\\nðŸŽ¯ HitRate@3: {hr3:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T03:38:30.896106Z","iopub.execute_input":"2025-08-04T03:38:30.896504Z","iopub.status.idle":"2025-08-04T03:56:43.876789Z","shell.execute_reply.started":"2025-08-04T03:38:30.896474Z","shell.execute_reply":"2025-08-04T03:56:43.875486Z"}},"outputs":[{"name":"stdout","text":"\nðŸŽ¯ HitRate@3: 0.0059\n","output_type":"stream"}],"execution_count":13}]}