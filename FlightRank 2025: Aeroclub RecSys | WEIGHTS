{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.18","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":105399,"databundleVersionId":12733338,"sourceType":"competition"},{"sourceId":12700104,"sourceType":"datasetVersion","datasetId":7902293}],"dockerImageVersionId":31091,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm\n\n# ---------------------------\n# Configuration\n# ---------------------------\nCONFIG = {\n    'data_paths': {\n        'competition': '/kaggle/input/aeroclub-recsys-2025/',\n        'submissions': '/kaggle/input/20-juli-2025-flightrank/',\n        'output': '/kaggle/working/'\n    },\n    'top_submissions': [\n        '0.49343.csv',  # XGBoost Ranker + Rule-based Rerank\n        '0.48425.csv',  # Simple Ensemble\n        '0.49068.csv',  # High scoring submission\n        '0.43916.csv'   # CatBoost baseline for diversity\n    ],\n    'ensemble_weights': [0.50, 0.30, 0.15, 0.05],\n    'final_blend_weights': [0.985, 0.006, 0.006, 0.003]\n}\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-09T18:01:04.395897Z","iopub.execute_input":"2025-08-09T18:01:04.396710Z","iopub.status.idle":"2025-08-09T18:01:04.410108Z","shell.execute_reply.started":"2025-08-09T18:01:04.396678Z","shell.execute_reply":"2025-08-09T18:01:04.405462Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ---------------------------\n# Helper Functions\n# ---------------------------\n\ndef safe_load_submission(path, file):\n    \"\"\"Safely load a submission file with validation\"\"\"\n    full_path = os.path.join(path, f\"submission {file}\" if ' ' not in file else file)\n    if not os.path.exists(full_path):\n        print(f\"Warning: Submission not found - {file}\")\n        return None\n    try:\n        df = pd.read_csv(full_path)\n        if not all(col in df.columns for col in ['Id', 'ranker_id', 'selected']):\n            print(f\"Warning: Invalid columns in {file}\")\n            return None\n        return df\n    except Exception as e:\n        print(f\"Error loading {file}: {str(e)}\")\n        return None\n\ndef rank_to_score(rank_series, eps=1e-6):\n    \"\"\"Convert ranks to normalized scores (1 = best rank)\"\"\"\n    max_rank = rank_series.max()\n    return 1.0 - (rank_series - 1) / (max_rank + eps)\n\ndef score_to_rank(score_series):\n    \"\"\"Convert scores back to ranks (1 = best score)\"\"\"\n    return score_series.rank(method='first', ascending=False).astype(int)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T18:01:04.413374Z","iopub.execute_input":"2025-08-09T18:01:04.413574Z","iopub.status.idle":"2025-08-09T18:01:04.426649Z","shell.execute_reply.started":"2025-08-09T18:01:04.413553Z","shell.execute_reply":"2025-08-09T18:01:04.423223Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ---------------------------\n# Ensemble Logic\n# ---------------------------\n\ndef create_weighted_ensemble(submissions, weights):\n    \"\"\"\n    Create weighted ensemble of multiple submissions\n    submissions: Dictionary of {submission_name: dataframe}\n    weights: List of weights corresponding to submissions\n    \"\"\"\n    # Convert each submission's ranks to normalized scores\n    scored_subs = []\n    for name, df in submissions.items():\n        if df is not None:\n            temp = df.copy()\n            temp['score'] = temp.groupby('ranker_id')['selected'].transform(rank_to_score)\n            scored_subs.append(temp[['Id', 'ranker_id', 'score']].rename(columns={'score': name}))\n    \n    if len(scored_subs) < 2:\n        print(\"Error: Need at least 2 valid submissions for ensemble\")\n        return None\n        # Merge all scored submissions\n    merged = scored_subs[0]\n    for df in scored_subs[1:]:\n        merged = merged.merge(df, on=['Id', 'ranker_id'], how='left')\n    \n    # Apply weights and calculate weighted average\n    score_cols = list(submissions.keys())\n    merged['ensemble_score'] = merged[score_cols].mul(weights[:len(score_cols)]).sum(axis=1) / sum(weights[:len(score_cols)])\n    \n    # Convert back to ranks\n    merged['selected'] = merged.groupby('ranker_id')['ensemble_score'].transform(score_to_rank)\n    \n    return merged[['Id', 'ranker_id', 'selected']]\n\ndef validate_submission(submission):\n    \"\"\"Validate the submission format and ranks\"\"\"\n    if submission is None:\n        return False\n    \n    # Check required columns\n    required_cols = ['Id', 'ranker_id', 'selected']\n    if not all(col in submission.columns for col in required_cols):\n        print(\"Error: Missing required columns\")\n        return False\n    \n    # Check rank permutations\n    invalid_groups = 0\n    for _, group in submission.groupby('ranker_id'):\n        ranks = group['selected'].sort_values().tolist()\n        if ranks != list(range(1, len(ranks)+1)):\n            invalid_groups += 1\n    \n    if invalid_groups > 0:\n        print(f\"Warning: {invalid_groups} groups with invalid rank permutations\")\n    \n    return True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T18:01:04.429829Z","iopub.execute_input":"2025-08-09T18:01:04.430030Z","iopub.status.idle":"2025-08-09T18:01:04.444891Z","shell.execute_reply.started":"2025-08-09T18:01:04.430009Z","shell.execute_reply":"2025-08-09T18:01:04.439853Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\n# ---------------------------\n# Main Execution\n# ---------------------------\n\ndef main():\n    print(\"FlightRank 2025 Optimized Ensemble\\n\")\n    \n    # 1. Load all available submissions\n    print(\"Loading submission files...\")\n    submissions = {}\n    for file in CONFIG['top_submissions']:\n        df = safe_load_submission(CONFIG['data_paths']['submissions'], file)\n        if df is not None:\n            submissions[file] = df\n            print(f\"Loaded {file} with shape: {df.shape}\")\n    \n    if not submissions:\n        print(\"Error: No valid submissions found\")\n        return\n    \n    # 2. Create primary weighted ensemble\n    print(\"\\nCreating primary ensemble...\")\n    primary_ensemble = create_weighted_ensemble(\n        submissions, \n        CONFIG['ensemble_weights']\n    )\n    \n    if not validate_submission(primary_ensemble):\n        print(\"Error: Invalid primary ensemble\")\n        return\n    \n    # 3. Create final blend with additional submissions\n    print(\"\\nCreating final blend...\")\n    blend_dfs = [primary_ensemble]\n    for file in CONFIG['top_submissions'][1:]:  # Skip first (already in primary)\n        if file in submissions:\n            blend_dfs.append(submissions[file])\n    \n    # Convert each to scores and blend\n    scored_dfs = []\n    for i, df in enumerate(blend_dfs):\n        temp = df.copy()\n        temp['score'] = temp.groupby('ranker_id')['selected'].transform(rank_to_score)\n        scored_dfs.append(temp[['Id', 'ranker_id', 'score']].rename(columns={'score': f'score_{i}'}))\n    \n    # Merge all scored submissions\n    merged = scored_dfs[0]\n    for df in scored_dfs[1:]:\n        merged = merged.merge(df, on=['Id', 'ranker_id'], how='left')\n    \n    # Apply final blend weights\n    score_cols = [f'score_{i}' for i in range(len(scored_dfs))]\n    merged['final_score'] = merged[score_cols].mul(CONFIG['final_blend_weights']).sum(axis=1) / sum(CONFIG['final_blend_weights'])\n    \n    # Convert to final ranks\n    merged['selected'] = merged.groupby('ranker_id')['final_score'].transform(score_to_rank)\n    final_submission = merged[['Id', 'ranker_id', 'selected']]\n    \n    # 4. Validate and save\n    if validate_submission(final_submission):\n        output_path = os.path.join(CONFIG['data_paths']['output'], 'submission.csv')\n        final_submission.to_csv(output_path, index=False)\n        print(f\"\\nSuccessfully saved submission to: {output_path}\")\n        \n        # Show summary stats\n        print(\"\\nSubmission summary:\")\n        print(f\"- Rows: {len(final_submission)}\")\n        print(f\"- Unique ranker_ids: {final_submission['ranker_id'].nunique()}\")\n        print(\"- Rank distribution:\")\n        print(final_submission['selected'].value_counts().sort_index().head(10))\n    else:\n        print(\"Error: Final submission validation failed\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T18:01:04.446881Z","iopub.execute_input":"2025-08-09T18:01:04.447110Z","iopub.status.idle":"2025-08-09T18:05:03.683957Z","shell.execute_reply.started":"2025-08-09T18:01:04.447088Z","shell.execute_reply":"2025-08-09T18:05:03.678985Z"}},"outputs":[{"name":"stdout","text":"FlightRank 2025 Optimized Ensemble\n\nLoading submission files...\nLoaded 0.49343.csv with shape: (6897776, 3)\nLoaded 0.48425.csv with shape: (6897776, 3)\nLoaded 0.49068.csv with shape: (6897776, 3)\nLoaded 0.43916.csv with shape: (6897776, 3)\n\nCreating primary ensemble...\n\nCreating final blend...\n\nSuccessfully saved submission to: /kaggle/working/submission.csv\n\nSubmission summary:\n- Rows: 6897776\n- Unique ranker_ids: 45231\n- Rank distribution:\nselected\n1     45231\n2     44347\n3     43120\n4     41915\n5     41102\n6     40615\n7     39389\n8     38946\n9     38282\n10    37258\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":4}]}